{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T15:42:30.890422Z","iopub.status.busy":"2021-12-09T15:42:30.890036Z","iopub.status.idle":"2021-12-09T15:42:37.774794Z","shell.execute_reply":"2021-12-09T15:42:37.774062Z","shell.execute_reply.started":"2021-12-09T15:42:30.890331Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-01 20:42:18.286002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-01 20:42:19.773601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n","2022-12-01 20:42:19.773694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n","2022-12-01 20:42:19.773701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from tensorflow.python.keras.layers import *\n","from tensorflow.python.keras.models import Model\n","import numpy as np \n","import pandas as pd \n","import re\n","import nltk\n","from preprocess import *\n","# from models import *"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T15:42:52.454527Z","iopub.status.busy":"2021-12-09T15:42:52.453714Z","iopub.status.idle":"2021-12-09T15:43:01.326923Z","shell.execute_reply":"2021-12-09T15:43:01.326227Z","shell.execute_reply.started":"2021-12-09T15:42:52.454487Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  What is the step by step guide to invest in sh...   \n","1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n","2   2     5     6  How can I increase the speed of my internet co...   \n","3   3     7     8  Why am I mentally very lonely? How can I solve...   \n","4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n","\n","                                           question2  is_duplicate  \n","0  What is the step by step guide to invest in sh...             0  \n","1  What would happen if the Indian government sto...             0  \n","2  How can Internet speed be increased by hacking...             0  \n","3  Find the remainder when [math]23^{24}[/math] i...             0  \n","4            Which fish would survive in salt water?             0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"questions.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-07T01:21:29.482516Z","iopub.status.busy":"2021-12-07T01:21:29.482071Z","iopub.status.idle":"2021-12-07T01:21:29.56485Z","shell.execute_reply":"2021-12-07T01:21:29.564017Z","shell.execute_reply.started":"2021-12-07T01:21:29.482481Z"},"trusted":true},"outputs":[],"source":["# question_1, question_2 = df['question1'].to_list(), df['question2'].to_list()\n","# is_duplicate = df['is_duplicate'].to_list()\n","# preprocess_neural(question_1, question_2, is_duplicate)"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["df1 = pd.read_csv(\"preprocessed_neural.csv\")\n","q1_preprocessed, q2_preprocessed, is_duplicate = df1['question1'].to_list(), df1['question2'].to_list(), df1['is_duplicate'].to_list()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# change all 0 to 0 1 and 1 to 1 0\n","for i in range(len(is_duplicate)):\n","    if is_duplicate[i] == 0:\n","        is_duplicate[i] = [0,1]\n","    else:\n","        is_duplicate[i] = [1,0]"]},{"cell_type":"markdown","metadata":{},"source":["Acquired Test data"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["MAX_WORDS_VOCAB = 200000\n","tokenizer = Tokenizer(num_words = MAX_WORDS_VOCAB)\n","tokenizer.fit_on_texts(list(df1['question1'].values.astype(str))+list(df1['question2'].values.astype(str)))"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["\n","q1_sequence = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\n","q1_sequence = pad_sequences(q1_sequence, maxlen = 30, padding='post')\n","\n","q2_sequence = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\n","q2_sequence = pad_sequences(q2_sequence, maxlen = 30, padding='post')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["windex = tokenizer.word_index"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["embedding_index = {}\n","with open('glove.6B.300d.txt','r') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vectors = np.asarray(values[1:], 'float32')\n","        embedding_index[word] = vectors\n","    f.close()"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(108101, 300)\n"]}],"source":["embedding_matrix = np.random.random((len(windex)+1, 300))\n","\n","for word, i in windex.items():\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","print(embedding_matrix.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#split the data into 70-20-10 train-validation-test with random state 42\n","from sklearn.model_selection import train_test_split\n","q1_train, q1_test, q2_train, q2_test, y_train, y_test = train_test_split(q1_sequence, q2_sequence, is_duplicate, test_size=0.1, random_state=42)\n","q1_train, q1_val, q2_train, q2_val, y_train, y_val = train_test_split(q1_train, q2_train, y_train, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(291132, 30) (40436, 30) (72783, 30)\n"]}],"source":["print(q1_train.shape, q1_test.shape, q1_val.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train:  [0.36998338 0.63001662]\n","Validation:  [0.36640424 0.63359576]\n","Test:  [0.36907706 0.63092294]\n"]}],"source":["#print the ratio of positive and negative samples in train, validation and test\n","y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\n","print(\"Train: \", sum(y_train)/len(y_train))\n","print(\"Validation: \", sum(y_val)/len(y_val))\n","print(\"Test: \", sum(y_test)/len(y_test))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["model = LSTM(embedding_matrix, vocab_size = len(windex) + 1)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["model.train_model()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(72783, 30)\n"]}],"source":["print(q1_val.shape)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","3635/4549 [======================>.......] - ETA: 42s - loss: 0.6477 - accuracy: 0.6300"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/jeopardy/Desktop/projects/quora-pairs/smai-project-lstm.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-lstm.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit([q1_train, q2_train], y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m ([q1_val, q2_val], y_val), batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m, validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1188\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.model.fit([q1_train, q2_train], y_train, epochs = 10, validation_data = ([q1_val, q2_val], y_val), batch_size = 64, validation_batch_size=32, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:  0.6325056880007913\n","F1 Score:  0.7164122137404579\n"]}],"source":["y_pred = model.predict([q1_test, q2_test])\n","y_pred1d, y_actual1d = [], []\n","for i in range(len(y_test)):\n","    if(y_test[i][0] == 1):\n","        y_actual1d.append(0)\n","    else:\n","        y_actual1d.append(1)\n","\n","for i in range(len(y_pred)):\n","    if(y_pred[i][0] > y_pred[i][1]):\n","        y_pred1d.append(0)\n","    else:\n","        y_pred1d.append(1)\n","\n","from sklearn.metrics import accuracy_score, f1_score\n","print(\"Accuracy: \", accuracy_score(y_actual1d, y_pred1d))\n","print(\"F1 Score: \", f1_score(y_actual1d, y_pred1d))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
