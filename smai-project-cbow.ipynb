{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T15:42:30.890422Z","iopub.status.busy":"2021-12-09T15:42:30.890036Z","iopub.status.idle":"2021-12-09T15:42:37.774794Z","shell.execute_reply":"2021-12-09T15:42:37.774062Z","shell.execute_reply.started":"2021-12-09T15:42:30.890331Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-01 05:00:07.236228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-01 05:00:08.682702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n","2022-12-01 05:00:08.682788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n","2022-12-01 05:00:08.682795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from tensorflow.python.keras.layers import *\n","from tensorflow.python.keras.models import Model\n","import numpy as np \n","import pandas as pd \n","import re\n","import nltk\n","from preprocess import *\n","# from models import *"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T15:42:52.454527Z","iopub.status.busy":"2021-12-09T15:42:52.453714Z","iopub.status.idle":"2021-12-09T15:43:01.326923Z","shell.execute_reply":"2021-12-09T15:43:01.326227Z","shell.execute_reply.started":"2021-12-09T15:42:52.454487Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  What is the step by step guide to invest in sh...   \n","1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n","2   2     5     6  How can I increase the speed of my internet co...   \n","3   3     7     8  Why am I mentally very lonely? How can I solve...   \n","4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n","\n","                                           question2  is_duplicate  \n","0  What is the step by step guide to invest in sh...             0  \n","1  What would happen if the Indian government sto...             0  \n","2  How can Internet speed be increased by hacking...             0  \n","3  Find the remainder when [math]23^{24}[/math] i...             0  \n","4            Which fish would survive in salt water?             0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"questions.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-07T01:21:29.482516Z","iopub.status.busy":"2021-12-07T01:21:29.482071Z","iopub.status.idle":"2021-12-07T01:21:29.56485Z","shell.execute_reply":"2021-12-07T01:21:29.564017Z","shell.execute_reply.started":"2021-12-07T01:21:29.482481Z"},"trusted":true},"outputs":[],"source":["# question_1, question_2 = df['question1'].to_list(), df['question2'].to_list()\n","# is_duplicate = df['is_duplicate'].to_list()\n","# preprocess_neural(question_1, question_2, is_duplicate)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["df1 = pd.read_csv(\"preprocessed_neural.csv\")\n","q1_preprocessed, q2_preprocessed, is_duplicate = df1['question1'].to_list(), df1['question2'].to_list(), df1['is_duplicate'].to_list()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>step step guide invest share market india</td>\n","      <td>step step guide invest share market</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>story kohinoor kohinoor diamond</td>\n","      <td>would happen indian government stole kohinoor ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>increase speed internet connection using vpn</td>\n","      <td>internet speed increased hacking dns</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>mentally lonely solve</td>\n","      <td>find remainder math2324math divided 2423</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>one dissolve water quikly sugar salt methane c...</td>\n","      <td>fish would survive salt water</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           question1  \\\n","0          step step guide invest share market india   \n","1                    story kohinoor kohinoor diamond   \n","2       increase speed internet connection using vpn   \n","3                              mentally lonely solve   \n","4  one dissolve water quikly sugar salt methane c...   \n","\n","                                           question2  is_duplicate  \n","0                step step guide invest share market             0  \n","1  would happen indian government stole kohinoor ...             0  \n","2               internet speed increased hacking dns             0  \n","3           find remainder math2324math divided 2423             0  \n","4                      fish would survive salt water             0  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df1.head()"]},{"cell_type":"markdown","metadata":{},"source":["Acquired Test data"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["MAX_NB_WORDS = 200000\n","tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n","tokenizer.fit_on_texts(list(df1['question1'].values.astype(str))+list(df1['question2'].values.astype(str)))"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["\n","q1_sequence = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\n","q1_sequence = pad_sequences(q1_sequence, maxlen = 30, padding='post')\n","\n","q2_sequence = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\n","q2_sequence = pad_sequences(q2_sequence, maxlen = 30, padding='post')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["windex = tokenizer.word_index"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["embedding_index = {}\n","with open('glove.6B.300d.txt','r') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vectors = np.asarray(values[1:], 'float32')\n","        embedding_index[word] = vectors\n","    f.close()"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(108101, 300)\n"]}],"source":["embedding_matrix = np.random.random((len(windex)+1, 300))\n","\n","for word, i in windex.items():\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","print(embedding_matrix.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["q1_embeddings = []\n","for i in range(len(q1_sequence)):\n","    embedding = np.zeros(300)\n","    for j in range(len(q1_sequence[i])):\n","        embedding += embedding_matrix[q1_sequence[i][j]]\n","    embedding /= len(q1_sequence[i])\n","    q1_embeddings.append(embedding)\n","\n","q2_embeddings = []\n","for i in range(len(q2_sequence)):\n","    embedding = np.zeros(300)\n","    for j in range(len(q2_sequence[i])):\n","        embedding += embedding_matrix[q2_sequence[i][j]]\n","    embedding /= len(q2_sequence[i])\n","    q2_embeddings.append(embedding)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["#split the data into 70-20-10 train-validation-test with random state 42\n","from sklearn.model_selection import train_test_split\n","q1_train, q1_test, q2_train, q2_test, y_train, y_test = train_test_split(q1_embeddings, q2_embeddings, is_duplicate, test_size=0.1, random_state=42)\n","q1_train, q1_val, q2_train, q2_val, y_train, y_val = train_test_split(q1_train, q2_train, y_train, test_size=0.222, random_state=42)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train:  0.36970242825607064\n","Validation:  0.3677435326154227\n","Test:  0.369077060045504\n"]}],"source":["#print the ratio of positive and negative samples in train, validation and test\n","print(\"Train: \", sum(y_train)/len(y_train))\n","print(\"Validation: \", sum(y_val)/len(y_val))\n","print(\"Test: \", sum(y_test)/len(y_test))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def concatenate_embeddings(q1_embeddings, q2_embeddings):\n","    embeddings = np.zeros((len(q1_embeddings), 600))\n","    for i in range(len(q1_embeddings)):\n","        embeddings[i] = np.concatenate((q1_embeddings[i], q2_embeddings[i]))\n","xtrain_concat = concatenate_embeddings(q1_train, q2_train)\n","xval_concat = concatenate_embeddings(q1_val, q2_val)\n","xtest_concat = concatenate_embeddings(q1_test, q2_test)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'shape'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(xval_concat\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(xtrain_concat\u001b[39m.\u001b[39mshape)\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}],"source":["print(xval_concat.shape)\n","print(xtrain_concat.shape)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# %load models.py\n","from tensorflow.python.keras.layers import *\n","from tensorflow.python.keras.models import Model\n","import tensorflow as tf\n","import numpy as np \n","from keras import Sequential\n","\n","class NeuralModels:\n","    def __init__(self, emb_mat, vocab_size = -1, loss = \"binary_crossentropy\", epochs = 10, optimizer = \"adam\", metrics = [\"accuracy\"]):\n","        self.epochs = epochs\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.vocab_size = vocab_size\n","        self.embedding_matrix = emb_mat\n","        self.model = Sequential()\n","\n","class CBOW(NeuralModels):\n","    def __init__(self, emb_mat, vocab_size = -1, loss = \"binary_crossentropy\", epochs = 10, optimizer = \"adam\", metrics = [\"accuracy\"]):\n","        super().__init__(emb_mat, vocab_size, loss, epochs, optimizer, metrics)\n","    \n","    def fit(self,xtrain, xval, ytrain, yval):\n","        self.model.add(Dense(300, input_shape = (600,), activation = \"relu\"))\n","        self.model.add(Dropout(0.1))\n","        self.model.add(Dense(200, activation = \"relu\"))\n","        self.model.add(Dropout(0.1))\n","        self.model.add(Dense(100, activation = \"relu\"))\n","        self.model.add(Dropout(0.1))\n","        self.model.add(Dense(1, activation = \"softmax\"))\n","        self.model.compile(loss = self.loss, optimizer = self.optimizer, metrics = self.metrics)\n","        self.model.fit(xtrain, ytrain, epochs = self.epochs, validation_data = (xval, yval), batch_size = 64, verbose = 1)\n","\n","    def get_model_summary(self):\n","        self.model.summary()\n","    \n","    def predict(self, xtest):\n","        return self.model.predict(xtest)\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["model = CBOW(embedding_matrix, embedding_matrix.shape[0], loss=\"binary_crossentropy\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xtrain_concat, xval_concat, y_train, y_val \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(xtrain_concat), np\u001b[39m.\u001b[39marray(xval_concat), np\u001b[39m.\u001b[39marray(y_train), np\u001b[39m.\u001b[39marray(y_val)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(xtrain_concat, xval_concat, y_train, y_val)\n","\u001b[1;32m/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb Cell 19\u001b[0m in \u001b[0;36mCBOW.fit\u001b[0;34m(self, xtrain, xval, ytrain, yval)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss, optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jeopardy/Desktop/projects/quora-pairs/smai-project-cbow.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(xtrain, ytrain, epochs \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, validation_data \u001b[39m=\u001b[39;49m (xval, yval), batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."]}],"source":["xtrain_concat, xval_concat, y_train, y_val = np.array(xtrain_concat), np.array(xval_concat), np.array(y_train), np.array(y_val)\n","model.fit(xtrain_concat, xval_concat, y_train, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
