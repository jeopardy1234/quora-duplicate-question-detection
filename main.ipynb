{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/jeopardy/.local/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /home/jeopardy/.local/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/jeopardy/.local/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jeopardy/.local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jeopardy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'is', \"n't\", 'a', 'moronic', 'bastard', '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"He isn't a moronic bastard.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    #if q is not a string, return empty string\n",
    "    if not isinstance(q, str):\n",
    "        return ''\n",
    "    q = q.lower()\n",
    "    nltk_tokens = nltk.word_tokenize(q)\n",
    "    return nltk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "df = pd.read_csv('questions.csv')\n",
    "# df['question1'] = df['question1'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df.set_index('qid1')['question1'].to_dict()\n",
    "questions.update(df.set_index('qid2')['question2'].to_dict())\n",
    "#preprocess the questions\n",
    "questions = {k: preprocess(v) for k, v in questions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions to unique questions: 0.5854104177694133\n"
     ]
    }
   ],
   "source": [
    "#make a new dataframe with duplicate questions while dropping question1 and question2 columns\n",
    "df = df.drop(['question1', 'question2'], axis=1)\n",
    "duplicate_questions = df[df['is_duplicate'] == 1]\n",
    "unique_questions = df[df['is_duplicate'] == 0]\n",
    "\n",
    "RATIO_DUP_UNIQUE = len(duplicate_questions) / len(unique_questions)\n",
    "print(\"Ratio of duplicate questions to unique questions: {}\".format(RATIO_DUP_UNIQUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into 70-20-10 while keeping the ratio of duplicate questions to unique questions\n",
    "train, validate, test = np.split(duplicate_questions.sample(frac=1), [int(.7*len(duplicate_questions)), int(.9*len(duplicate_questions))])\n",
    "train = pd.concat([train, unique_questions.sample(frac=0.7)], ignore_index=True)\n",
    "validate = pd.concat([validate, unique_questions.sample(frac=0.2)], ignore_index=True)\n",
    "test = pd.concat([test, unique_questions.sample(frac=0.1)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions to unique questions in train set: 0.5854076580108888\n"
     ]
    }
   ],
   "source": [
    "train_duplicate_questions = train[train['is_duplicate'] == 1]\n",
    "train_unique_questions = train[train['is_duplicate'] == 0]\n",
    "print(\"Ratio of duplicate questions to unique questions in train set: {}\".format(len(train_duplicate_questions) / len(train_unique_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions to unique questions in test set: 0.5854375784190715\n"
     ]
    }
   ],
   "source": [
    "test_duplicate_questions = test[test['is_duplicate'] == 1]\n",
    "test_unique_questions = test[test['is_duplicate'] == 0]\n",
    "print(\"Ratio of duplicate questions to unique questions in test set: {}\".format(len(test_duplicate_questions) / len(test_unique_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions to unique questions in validate set: 0.5854064968927052\n"
     ]
    }
   ],
   "source": [
    "validate_duplicate_questions = validate[validate['is_duplicate'] == 1]\n",
    "validate_unique_questions = validate[validate['is_duplicate'] == 0]\n",
    "\n",
    "print(\"Ratio of duplicate questions to unique questions in validate set: {}\".format(len(validate_duplicate_questions) / len(validate_unique_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
