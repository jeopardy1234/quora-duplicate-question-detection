{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nemesis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nemesis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions in the splits\n",
      "Train set:  0.36919749967314835\n",
      "Validation set:  0.36920279997031835\n",
      "Test set:  0.369190432610255\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('questions.csv.zip')\n",
    "df.dropna(how=\"any\").reset_index(drop=True)\n",
    "\n",
    "# train validate test split 70:20:10\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_q1, X_test_q1, X_train_q2, X_test_q2, y_train, y_test = train_test_split(df['question1'], df['question2'], df['is_duplicate'], test_size=0.3, random_state=42, stratify=df['is_duplicate'])\n",
    "X_val_q1, X_test_q1, X_val_q2, X_test_q2, y_val, y_test = train_test_split(X_test_q1, X_test_q2, y_test, test_size=(1/3), random_state=42, stratify=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of duplicate questions in the splits\n",
      "Train set:  0.36919749967314835\n",
      "Validation set:  0.36920279997031835\n",
      "Test set:  0.369190432610255\n"
     ]
    }
   ],
   "source": [
    "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\n",
    "# ratio of duplicate questions in train, validation and test set\n",
    "print(\"Ratio of duplicate questions in the splits\")\n",
    "print(\"Train set: \", y_train.sum()/len(y_train))\n",
    "print(\"Validation set: \", y_val.sum()/len(y_val))\n",
    "print(\"Test set: \", y_test.sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = './input/'\n",
    "TRAIN_LINEAR_PATH = INPUT + 'train_linear.csv.zip'\n",
    "TEST_LINEAR_PATH = INPUT + 'test_linear.csv.zip'\n",
    "VAL_LINEAR_PATH = INPUT + 'val_linear.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear = pd.DataFrame({'question1': X_train_q1, 'question2': X_train_q2, 'is_duplicate': y_train})\n",
    "val_linear = pd.DataFrame({'question1': X_val_q1, 'question2': X_val_q2, 'is_duplicate': y_val})\n",
    "test_linear = pd.DataFrame({'question1': X_test_q1, 'question2': X_test_q2, 'is_duplicate': y_test})\n",
    "allQuestions = pd.concat((train_linear['question1'], train_linear['question2'])).reset_index(drop=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump split files\n",
    "os.makedirs(INPUT, exist_ok=True)  \n",
    "train_linear.to_csv(TRAIN_LINEAR_PATH, index=False, compression='zip')\n",
    "val_linear.to_csv(VAL_LINEAR_PATH, index=False, compression='zip')\n",
    "test_linear.to_csv(TEST_LINEAR_PATH, index=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear = pd.read_csv(TRAIN_LINEAR_PATH)\n",
    "val_linear = pd.read_csv(VAL_LINEAR_PATH)\n",
    "test_linear = pd.read_csv(TEST_LINEAR_PATH)\n",
    "X_train_q1, X_train_q2, y_train = train_linear['question1'].astype('U').values, train_linear['question2'].astype('U').values, train_linear['is_duplicate'].values\n",
    "X_val_q1, X_val_q2, y_val = val_linear['question1'].astype('U').values, val_linear['question2'].astype('U').values, val_linear['is_duplicate'].values\n",
    "X_test_q1, X_test_q2, y_test = test_linear['question1'].astype('U').values, test_linear['question2'].astype('U').values, test_linear['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack as sparse_hstack, vstack as sparse_vstack, save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    tokens = nltk.word_tokenize(re.sub(r'[^\\x00-\\x7F]+',' ', text))\n",
    "    tokens = [stemmer.stem(w) for w in tokens if stemmer.stem(w) not in stopwords]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAMS_PATH = './n_gram_features/'\n",
    "UNIGRAM_PATH = N_GRAMS_PATH + 'unigrams_linear/'\n",
    "BIGRAM_PATH = N_GRAMS_PATH + 'bigrams_linear/'\n",
    "TRIGRAM_PATH = N_GRAMS_PATH + 'trigrams_linear/'\n",
    "os.makedirs(N_GRAMS_PATH, exist_ok=True)\n",
    "os.makedirs(UNIGRAM_PATH, exist_ok=True)\n",
    "os.makedirs(BIGRAM_PATH, exist_ok=True)\n",
    "os.makedirs(TRIGRAM_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Unigram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramVectorizer = CountVectorizer(\n",
    "                        analyzer='word', \n",
    "                        ngram_range=(1,1), \n",
    "                        lowercase=True,\n",
    "                        tokenizer=tokenize\n",
    "                    )\n",
    "                    \n",
    "unigramVectorizer.fit(allQuestions)\n",
    "q1_train = unigramVectorizer.transform(train_linear['question1'].astype(str))\n",
    "q2_train = unigramVectorizer.transform(train_linear['question2'].astype(str))\n",
    "X_train_unigram = sparse_hstack([q1_train, q2_train])\n",
    "q1_val = unigramVectorizer.transform(val_linear['question1'].astype(str))\n",
    "q2_val = unigramVectorizer.transform(val_linear['question2'].astype(str))\n",
    "X_val_unigram = sparse_hstack([q1_val, q2_val])\n",
    "q1_test = unigramVectorizer.transform(test_linear['question1'].astype(str))\n",
    "q2_test = unigramVectorizer.transform(test_linear['question2'].astype(str))\n",
    "X_test_unigram = sparse_hstack([q1_test, q2_test])\n",
    "\n",
    "save_npz(UNIGRAM_PATH + \"train.npz\", X_train_unigram)\n",
    "save_npz(UNIGRAM_PATH + \"val.npz\", X_val_unigram)\n",
    "save_npz(UNIGRAM_PATH + \"test.npz\", X_test_unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bigram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramVectorizer = CountVectorizer(\n",
    "                        analyzer='word', \n",
    "                        ngram_range=(1,2), \n",
    "                        lowercase=True,\n",
    "                        tokenizer=tokenize\n",
    "                    )\n",
    "                    \n",
    "bigramVectorizer.fit(allQuestions)\n",
    "q1_train = bigramVectorizer.transform(train_linear['question1'].astype(str))\n",
    "q2_train = bigramVectorizer.transform(train_linear['question2'].astype(str))\n",
    "X_train_bigram = sparse_hstack([q1_train, q2_train])\n",
    "q1_val = bigramVectorizer.transform(val_linear['question1'].astype(str))\n",
    "q2_val = bigramVectorizer.transform(val_linear['question2'].astype(str))\n",
    "X_val_bigram = sparse_hstack([q1_val, q2_val])\n",
    "q1_test = bigramVectorizer.transform(test_linear['question1'].astype(str))\n",
    "q2_test = bigramVectorizer.transform(test_linear['question2'].astype(str))\n",
    "X_test_bigram = sparse_hstack([q1_test, q2_test])\n",
    "\n",
    "save_npz(BIGRAM_PATH + \"train.npz\", X_train_bigram)\n",
    "save_npz(BIGRAM_PATH + \"val.npz\", X_val_bigram)\n",
    "save_npz(BIGRAM_PATH + \"test.npz\", X_test_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Trigram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramVectorizer = CountVectorizer(\n",
    "                        analyzer='word', \n",
    "                        ngram_range=(1,3), \n",
    "                        lowercase=True,\n",
    "                        tokenizer=tokenize\n",
    "                    )\n",
    "                    \n",
    "trigramVectorizer.fit(allQuestions)\n",
    "q1_train = trigramVectorizer.transform(train_linear['question1'].astype(str))\n",
    "q2_train = trigramVectorizer.transform(train_linear['question2'].astype(str))\n",
    "X_train_trigram = sparse_hstack([q1_train, q2_train])\n",
    "q1_val = trigramVectorizer.transform(val_linear['question1'].astype(str))\n",
    "q2_val = trigramVectorizer.transform(val_linear['question2'].astype(str))\n",
    "X_val_trigram = sparse_hstack([q1_val, q2_val])\n",
    "q1_test = trigramVectorizer.transform(test_linear['question1'].astype(str))\n",
    "q2_test = trigramVectorizer.transform(test_linear['question2'].astype(str))\n",
    "X_test_trigram = sparse_hstack([q1_test, q2_test])\n",
    "\n",
    "save_npz(TRIGRAM_PATH + \"train.npz\", X_train_trigram)\n",
    "save_npz(TRIGRAM_PATH + \"val.npz\", X_val_trigram)\n",
    "save_npz(TRIGRAM_PATH + \"test.npz\", X_test_trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Logistic Regression Accuracy:  0.7418437260382399\n",
      "Unigram Logistic Regression F1 Score:  0.6310840903467534\n"
     ]
    }
   ],
   "source": [
    "# X_train_unigram = load_npz(UNIGRAM_PATH + \"train.npz\")\n",
    "# X_test_unigram = load_npz(UNIGRAM_PATH + \"test.npz\")\n",
    "unigramLogisticRegressor = SGDClassifier(\n",
    "                            loss='log_loss', \n",
    "                            penalty='l2', \n",
    "                            alpha=0.00001, \n",
    "                            max_iter=1000,\n",
    "                            n_iter_no_change=20,\n",
    "                            learning_rate='optimal',\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "unigramLogisticRegressor.fit(X_train_unigram, y_train)\n",
    "y_pred_unigram_logistic = unigramLogisticRegressor.predict(X_test_unigram)\n",
    "print(\"Unigram Logistic Regression Accuracy: \", accuracy_score(y_test, y_pred_unigram_logistic))\n",
    "print(\"Unigram Logistic Regression F1 Score: \", f1_score(y_test, y_pred_unigram_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram Logistic Regression Accuracy:  0.7962106408765984\n",
      "bigram Logistic Regression F1 Score:  0.7066405554566494\n"
     ]
    }
   ],
   "source": [
    "# X_train_bigram = load_npz(BIGRAM_PATH + \"train.npz\")\n",
    "# X_test_bigram = load_npz(BIGRAM_PATH + \"test.npz\")\n",
    "bigramLogisticRegressor = SGDClassifier(\n",
    "                            loss='log_loss', \n",
    "                            penalty='l2', \n",
    "                            alpha=0.00001, \n",
    "                            max_iter=1000,\n",
    "                            n_iter_no_change=20,\n",
    "                            learning_rate='optimal',\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "bigramLogisticRegressor.fit(X_train_bigram, y_train)\n",
    "y_pred_bigram_logistic = bigramLogisticRegressor.predict(X_test_bigram)\n",
    "print(\"bigram Logistic Regression Accuracy: \", accuracy_score(y_test, y_pred_bigram_logistic))\n",
    "print(\"bigram Logistic Regression F1 Score: \", f1_score(y_test, y_pred_bigram_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram Logistic Regression Accuracy:  0.8114472284746098\n",
      "trigram Logistic Regression F1 Score:  0.7147614593077642\n"
     ]
    }
   ],
   "source": [
    "# X_train_trigram = load_npz(TRIGRAM_PATH + \"train.npz\")\n",
    "# X_test_trigram = load_npz(TRIGRAM_PATH + \"test.npz\")\n",
    "trigramLogisticRegressor = SGDClassifier(\n",
    "                            loss='log_loss', \n",
    "                            penalty='l2', \n",
    "                            alpha=0.00001, \n",
    "                            max_iter=1000,\n",
    "                            n_iter_no_change=20,\n",
    "                            learning_rate='optimal',\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "trigramLogisticRegressor.fit(X_train_trigram, y_train)\n",
    "y_pred_trigram_logistic = trigramLogisticRegressor.predict(X_test_trigram)\n",
    "print(\"trigram Logistic Regression Accuracy: \", accuracy_score(y_test, y_pred_trigram_logistic))\n",
    "print(\"trigram Logistic Regression F1 Score: \", f1_score(y_test, y_pred_trigram_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying GridSearchCV on Trigrams model to get the best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SGDClassifier(loss=&#x27;log_loss&#x27;, n_jobs=-1,\n",
       "                                     random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.001, 0.0001, 1e-05, 1e-06],\n",
       "                         &#x27;n_iter_no_change&#x27;: [5, 10, 15, 20]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SGDClassifier(loss=&#x27;log_loss&#x27;, n_jobs=-1,\n",
       "                                     random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.001, 0.0001, 1e-05, 1e-06],\n",
       "                         &#x27;n_iter_no_change&#x27;: [5, 10, 15, 20]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SGDClassifier(loss='log_loss', n_jobs=-1,\n",
       "                                     random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.001, 0.0001, 1e-05, 1e-06],\n",
       "                         'n_iter_no_change': [5, 10, 15, 20]},\n",
       "             refit='f1', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramLogisticRegressor = SGDClassifier(\n",
    "                            loss='log_loss',\n",
    "                            penalty='l2',\n",
    "                            max_iter=1000,\n",
    "                            learning_rate='optimal',\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "parameters = dict({\n",
    "                'alpha':[0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "                'n_iter_no_change': [5, 10, 15, 20]\n",
    "            })\n",
    "cv_stratifier_splitter = StratifiedKFold(n_splits=5)\n",
    "grid_search = GridSearchCV(trigramLogisticRegressor, \n",
    "                            parameters, \n",
    "                            cv=cv_stratifier_splitter, \n",
    "                            scoring=['accuracy', 'f1'], \n",
    "                            n_jobs=-1,\n",
    "                            refit='f1')\n",
    "grid_search.fit(sparse_vstack([X_train_trigram, X_val_trigram]), np.concatenate((y_train, y_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.057936</td>\n",
       "      <td>4.823794</td>\n",
       "      <td>1.462032</td>\n",
       "      <td>0.469907</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0.01, 'n_iter_no_change': 5}</td>\n",
       "      <td>0.692152</td>\n",
       "      <td>0.691969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>17</td>\n",
       "      <td>0.352870</td>\n",
       "      <td>0.351276</td>\n",
       "      <td>0.352789</td>\n",
       "      <td>0.354524</td>\n",
       "      <td>0.356614</td>\n",
       "      <td>0.353614</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34.839753</td>\n",
       "      <td>5.847555</td>\n",
       "      <td>1.570614</td>\n",
       "      <td>0.270366</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 0.01, 'n_iter_no_change': 10}</td>\n",
       "      <td>0.691190</td>\n",
       "      <td>0.691969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>18</td>\n",
       "      <td>0.347076</td>\n",
       "      <td>0.351426</td>\n",
       "      <td>0.348466</td>\n",
       "      <td>0.349686</td>\n",
       "      <td>0.349993</td>\n",
       "      <td>0.349329</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41.940447</td>\n",
       "      <td>10.329488</td>\n",
       "      <td>1.597674</td>\n",
       "      <td>0.275955</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 0.01, 'n_iter_no_change': 15}</td>\n",
       "      <td>0.691122</td>\n",
       "      <td>0.691461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>19</td>\n",
       "      <td>0.346570</td>\n",
       "      <td>0.348641</td>\n",
       "      <td>0.347652</td>\n",
       "      <td>0.350843</td>\n",
       "      <td>0.350410</td>\n",
       "      <td>0.348823</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>44.677039</td>\n",
       "      <td>6.685752</td>\n",
       "      <td>1.307405</td>\n",
       "      <td>0.393770</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 0.01, 'n_iter_no_change': 20}</td>\n",
       "      <td>0.690916</td>\n",
       "      <td>0.690843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>20</td>\n",
       "      <td>0.345848</td>\n",
       "      <td>0.345646</td>\n",
       "      <td>0.346039</td>\n",
       "      <td>0.347637</td>\n",
       "      <td>0.349897</td>\n",
       "      <td>0.347013</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24.846832</td>\n",
       "      <td>6.631401</td>\n",
       "      <td>1.670751</td>\n",
       "      <td>0.193314</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0.001, 'n_iter_no_change': 5}</td>\n",
       "      <td>0.741415</td>\n",
       "      <td>0.742827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>14</td>\n",
       "      <td>0.546314</td>\n",
       "      <td>0.550779</td>\n",
       "      <td>0.547320</td>\n",
       "      <td>0.547302</td>\n",
       "      <td>0.555941</td>\n",
       "      <td>0.549531</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>31.927570</td>\n",
       "      <td>2.169471</td>\n",
       "      <td>0.891322</td>\n",
       "      <td>0.097146</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 0.001, 'n_iter_no_change': 10}</td>\n",
       "      <td>0.742473</td>\n",
       "      <td>0.743638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>13</td>\n",
       "      <td>0.552838</td>\n",
       "      <td>0.556443</td>\n",
       "      <td>0.547028</td>\n",
       "      <td>0.549382</td>\n",
       "      <td>0.549654</td>\n",
       "      <td>0.551069</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>35.785039</td>\n",
       "      <td>6.948313</td>\n",
       "      <td>1.889833</td>\n",
       "      <td>0.513881</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 0.001, 'n_iter_no_change': 15}</td>\n",
       "      <td>0.741072</td>\n",
       "      <td>0.743129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>15</td>\n",
       "      <td>0.545130</td>\n",
       "      <td>0.551458</td>\n",
       "      <td>0.546284</td>\n",
       "      <td>0.545874</td>\n",
       "      <td>0.550921</td>\n",
       "      <td>0.547933</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>59.535236</td>\n",
       "      <td>2.297733</td>\n",
       "      <td>1.418594</td>\n",
       "      <td>0.290130</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 0.001, 'n_iter_no_change': 20}</td>\n",
       "      <td>0.741236</td>\n",
       "      <td>0.741796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>16</td>\n",
       "      <td>0.546055</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>0.539016</td>\n",
       "      <td>0.542346</td>\n",
       "      <td>0.547395</td>\n",
       "      <td>0.543864</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32.525184</td>\n",
       "      <td>8.522953</td>\n",
       "      <td>1.530440</td>\n",
       "      <td>0.418499</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 0.0001, 'n_iter_no_change': 5}</td>\n",
       "      <td>0.780660</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>9</td>\n",
       "      <td>0.652092</td>\n",
       "      <td>0.650675</td>\n",
       "      <td>0.650521</td>\n",
       "      <td>0.648484</td>\n",
       "      <td>0.657971</td>\n",
       "      <td>0.651949</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>49.180857</td>\n",
       "      <td>11.419878</td>\n",
       "      <td>1.625803</td>\n",
       "      <td>0.334466</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 0.0001, 'n_iter_no_change': 10}</td>\n",
       "      <td>0.780578</td>\n",
       "      <td>0.782719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>12</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.653565</td>\n",
       "      <td>0.643136</td>\n",
       "      <td>0.640263</td>\n",
       "      <td>0.642371</td>\n",
       "      <td>0.646010</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>40.283555</td>\n",
       "      <td>10.689865</td>\n",
       "      <td>1.386696</td>\n",
       "      <td>0.343637</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 0.0001, 'n_iter_no_change': 15}</td>\n",
       "      <td>0.780908</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>10</td>\n",
       "      <td>0.653647</td>\n",
       "      <td>0.655294</td>\n",
       "      <td>0.651344</td>\n",
       "      <td>0.648414</td>\n",
       "      <td>0.656066</td>\n",
       "      <td>0.652953</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>57.527124</td>\n",
       "      <td>5.102434</td>\n",
       "      <td>1.504030</td>\n",
       "      <td>0.103422</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 0.0001, 'n_iter_no_change': 20}</td>\n",
       "      <td>0.780688</td>\n",
       "      <td>0.782691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>11</td>\n",
       "      <td>0.650919</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>0.647006</td>\n",
       "      <td>0.647918</td>\n",
       "      <td>0.656548</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>33.256662</td>\n",
       "      <td>3.574577</td>\n",
       "      <td>1.443488</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 1e-05, 'n_iter_no_change': 5}</td>\n",
       "      <td>0.807332</td>\n",
       "      <td>0.808237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698025</td>\n",
       "      <td>0.714616</td>\n",
       "      <td>0.709538</td>\n",
       "      <td>0.707157</td>\n",
       "      <td>0.707429</td>\n",
       "      <td>0.707353</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>32.103819</td>\n",
       "      <td>3.748073</td>\n",
       "      <td>1.302405</td>\n",
       "      <td>0.426505</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 1e-05, 'n_iter_no_change': 10}</td>\n",
       "      <td>0.806453</td>\n",
       "      <td>0.807934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>4</td>\n",
       "      <td>0.713679</td>\n",
       "      <td>0.701722</td>\n",
       "      <td>0.710008</td>\n",
       "      <td>0.709509</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.710906</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>44.492694</td>\n",
       "      <td>0.965001</td>\n",
       "      <td>1.558569</td>\n",
       "      <td>0.328143</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 1e-05, 'n_iter_no_change': 15}</td>\n",
       "      <td>0.804680</td>\n",
       "      <td>0.808828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>2</td>\n",
       "      <td>0.713057</td>\n",
       "      <td>0.706113</td>\n",
       "      <td>0.711488</td>\n",
       "      <td>0.711608</td>\n",
       "      <td>0.715967</td>\n",
       "      <td>0.711647</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>58.558907</td>\n",
       "      <td>10.112322</td>\n",
       "      <td>1.424766</td>\n",
       "      <td>0.203237</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 1e-05, 'n_iter_no_change': 20}</td>\n",
       "      <td>0.806742</td>\n",
       "      <td>0.807426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>3</td>\n",
       "      <td>0.712181</td>\n",
       "      <td>0.711004</td>\n",
       "      <td>0.715343</td>\n",
       "      <td>0.710696</td>\n",
       "      <td>0.715824</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>39.761328</td>\n",
       "      <td>0.877920</td>\n",
       "      <td>1.103284</td>\n",
       "      <td>0.397345</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 1e-06, 'n_iter_no_change': 5}</td>\n",
       "      <td>0.802949</td>\n",
       "      <td>0.803784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>7</td>\n",
       "      <td>0.706448</td>\n",
       "      <td>0.698482</td>\n",
       "      <td>0.704552</td>\n",
       "      <td>0.708678</td>\n",
       "      <td>0.718208</td>\n",
       "      <td>0.707274</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>45.833273</td>\n",
       "      <td>3.359309</td>\n",
       "      <td>1.549358</td>\n",
       "      <td>0.397857</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 1e-06, 'n_iter_no_change': 10}</td>\n",
       "      <td>0.801602</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>5</td>\n",
       "      <td>0.708099</td>\n",
       "      <td>0.707074</td>\n",
       "      <td>0.710392</td>\n",
       "      <td>0.709978</td>\n",
       "      <td>0.715186</td>\n",
       "      <td>0.710146</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>56.188770</td>\n",
       "      <td>2.537069</td>\n",
       "      <td>1.026216</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 1e-06, 'n_iter_no_change': 15}</td>\n",
       "      <td>0.798497</td>\n",
       "      <td>0.802273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714152</td>\n",
       "      <td>0.715007</td>\n",
       "      <td>0.711416</td>\n",
       "      <td>0.706668</td>\n",
       "      <td>0.719169</td>\n",
       "      <td>0.713283</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>50.262399</td>\n",
       "      <td>7.179083</td>\n",
       "      <td>0.540624</td>\n",
       "      <td>0.348990</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 1e-06, 'n_iter_no_change': 20}</td>\n",
       "      <td>0.797260</td>\n",
       "      <td>0.799813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>8</td>\n",
       "      <td>0.712611</td>\n",
       "      <td>0.715613</td>\n",
       "      <td>0.713257</td>\n",
       "      <td>0.711372</td>\n",
       "      <td>0.716722</td>\n",
       "      <td>0.713915</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0      32.057936      4.823794         1.462032        0.469907   \n",
       "1       1      34.839753      5.847555         1.570614        0.270366   \n",
       "2       2      41.940447     10.329488         1.597674        0.275955   \n",
       "3       3      44.677039      6.685752         1.307405        0.393770   \n",
       "4       4      24.846832      6.631401         1.670751        0.193314   \n",
       "5       5      31.927570      2.169471         0.891322        0.097146   \n",
       "6       6      35.785039      6.948313         1.889833        0.513881   \n",
       "7       7      59.535236      2.297733         1.418594        0.290130   \n",
       "8       8      32.525184      8.522953         1.530440        0.418499   \n",
       "9       9      49.180857     11.419878         1.625803        0.334466   \n",
       "10     10      40.283555     10.689865         1.386696        0.343637   \n",
       "11     11      57.527124      5.102434         1.504030        0.103422   \n",
       "12     12      33.256662      3.574577         1.443488        0.112564   \n",
       "13     13      32.103819      3.748073         1.302405        0.426505   \n",
       "14     14      44.492694      0.965001         1.558569        0.328143   \n",
       "15     15      58.558907     10.112322         1.424766        0.203237   \n",
       "16     16      39.761328      0.877920         1.103284        0.397345   \n",
       "17     17      45.833273      3.359309         1.549358        0.397857   \n",
       "18     18      56.188770      2.537069         1.026216        0.285707   \n",
       "19     19      50.262399      7.179083         0.540624        0.348990   \n",
       "\n",
       "   param_alpha param_n_iter_no_change  \\\n",
       "0         0.01                      5   \n",
       "1         0.01                     10   \n",
       "2         0.01                     15   \n",
       "3         0.01                     20   \n",
       "4        0.001                      5   \n",
       "5        0.001                     10   \n",
       "6        0.001                     15   \n",
       "7        0.001                     20   \n",
       "8       0.0001                      5   \n",
       "9       0.0001                     10   \n",
       "10      0.0001                     15   \n",
       "11      0.0001                     20   \n",
       "12     0.00001                      5   \n",
       "13     0.00001                     10   \n",
       "14     0.00001                     15   \n",
       "15     0.00001                     20   \n",
       "16    0.000001                      5   \n",
       "17    0.000001                     10   \n",
       "18    0.000001                     15   \n",
       "19    0.000001                     20   \n",
       "\n",
       "                                       params  split0_test_accuracy  \\\n",
       "0      {'alpha': 0.01, 'n_iter_no_change': 5}              0.692152   \n",
       "1     {'alpha': 0.01, 'n_iter_no_change': 10}              0.691190   \n",
       "2     {'alpha': 0.01, 'n_iter_no_change': 15}              0.691122   \n",
       "3     {'alpha': 0.01, 'n_iter_no_change': 20}              0.690916   \n",
       "4     {'alpha': 0.001, 'n_iter_no_change': 5}              0.741415   \n",
       "5    {'alpha': 0.001, 'n_iter_no_change': 10}              0.742473   \n",
       "6    {'alpha': 0.001, 'n_iter_no_change': 15}              0.741072   \n",
       "7    {'alpha': 0.001, 'n_iter_no_change': 20}              0.741236   \n",
       "8    {'alpha': 0.0001, 'n_iter_no_change': 5}              0.780660   \n",
       "9   {'alpha': 0.0001, 'n_iter_no_change': 10}              0.780578   \n",
       "10  {'alpha': 0.0001, 'n_iter_no_change': 15}              0.780908   \n",
       "11  {'alpha': 0.0001, 'n_iter_no_change': 20}              0.780688   \n",
       "12    {'alpha': 1e-05, 'n_iter_no_change': 5}              0.807332   \n",
       "13   {'alpha': 1e-05, 'n_iter_no_change': 10}              0.806453   \n",
       "14   {'alpha': 1e-05, 'n_iter_no_change': 15}              0.804680   \n",
       "15   {'alpha': 1e-05, 'n_iter_no_change': 20}              0.806742   \n",
       "16    {'alpha': 1e-06, 'n_iter_no_change': 5}              0.802949   \n",
       "17   {'alpha': 1e-06, 'n_iter_no_change': 10}              0.801602   \n",
       "18   {'alpha': 1e-06, 'n_iter_no_change': 15}              0.798497   \n",
       "19   {'alpha': 1e-06, 'n_iter_no_change': 20}              0.797260   \n",
       "\n",
       "    split1_test_accuracy  ...  std_test_accuracy  rank_test_accuracy  \\\n",
       "0               0.691969  ...           0.000602                  17   \n",
       "1               0.691969  ...           0.000497                  18   \n",
       "2               0.691461  ...           0.000457                  19   \n",
       "3               0.690843  ...           0.000539                  20   \n",
       "4               0.742827  ...           0.001528                  14   \n",
       "5               0.743638  ...           0.001614                  13   \n",
       "6               0.743129  ...           0.001499                  15   \n",
       "7               0.741796  ...           0.001460                  16   \n",
       "8               0.782870  ...           0.001323                   9   \n",
       "9               0.782719  ...           0.001481                  12   \n",
       "10              0.782870  ...           0.001463                  10   \n",
       "11              0.782691  ...           0.001637                  11   \n",
       "12              0.808237  ...           0.001453                   1   \n",
       "13              0.807934  ...           0.001237                   4   \n",
       "14              0.808828  ...           0.001937                   2   \n",
       "15              0.807426  ...           0.001874                   3   \n",
       "16              0.803784  ...           0.003224                   7   \n",
       "17              0.802960  ...           0.002758                   5   \n",
       "18              0.802273  ...           0.001822                   6   \n",
       "19              0.799813  ...           0.002437                   8   \n",
       "\n",
       "    split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  \\\n",
       "0         0.352870        0.351276        0.352789        0.354524   \n",
       "1         0.347076        0.351426        0.348466        0.349686   \n",
       "2         0.346570        0.348641        0.347652        0.350843   \n",
       "3         0.345848        0.345646        0.346039        0.347637   \n",
       "4         0.546314        0.550779        0.547320        0.547302   \n",
       "5         0.552838        0.556443        0.547028        0.549382   \n",
       "6         0.545130        0.551458        0.546284        0.545874   \n",
       "7         0.546055        0.544507        0.539016        0.542346   \n",
       "8         0.652092        0.650675        0.650521        0.648484   \n",
       "9         0.650713        0.653565        0.643136        0.640263   \n",
       "10        0.653647        0.655294        0.651344        0.648414   \n",
       "11        0.650919        0.652103        0.647006        0.647918   \n",
       "12        0.698025        0.714616        0.709538        0.707157   \n",
       "13        0.713679        0.701722        0.710008        0.709509   \n",
       "14        0.713057        0.706113        0.711488        0.711608   \n",
       "15        0.712181        0.711004        0.715343        0.710696   \n",
       "16        0.706448        0.698482        0.704552        0.708678   \n",
       "17        0.708099        0.707074        0.710392        0.709978   \n",
       "18        0.714152        0.715007        0.711416        0.706668   \n",
       "19        0.712611        0.715613        0.713257        0.711372   \n",
       "\n",
       "    split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0         0.356614      0.353614     0.001818            17  \n",
       "1         0.349993      0.349329     0.001469            18  \n",
       "2         0.350410      0.348823     0.001617            19  \n",
       "3         0.349897      0.347013     0.001605            20  \n",
       "4         0.555941      0.549531     0.003546            14  \n",
       "5         0.549654      0.551069     0.003262            13  \n",
       "6         0.550921      0.547933     0.002690            15  \n",
       "7         0.547395      0.543864     0.002949            16  \n",
       "8         0.657971      0.651949     0.003223            10  \n",
       "9         0.642371      0.646010     0.005172            12  \n",
       "10        0.656066      0.652953     0.002787             9  \n",
       "11        0.656548      0.650899     0.003388            11  \n",
       "12        0.707429      0.707353     0.005377             7  \n",
       "13        0.719614      0.710906     0.005842             5  \n",
       "14        0.715967      0.711647     0.003203             4  \n",
       "15        0.715824      0.713009     0.002164             3  \n",
       "16        0.718208      0.707274     0.006433             8  \n",
       "17        0.715186      0.710146     0.002797             6  \n",
       "18        0.719169      0.713283     0.004138             2  \n",
       "19        0.716722      0.713915     0.001968             1  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCVResults = pd.DataFrame.from_dict(grid_search.cv_results_).reset_index()\n",
    "gridSearchCVResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Best Parameters</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'alpha': 1e-06, 'n_iter_no_change': 20}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram Tuned Logistic Regression Accuracy:  80.31116277919315\n",
      "trigram Tuned Logistic Regression F1 Score:  72.37454015409178\n"
     ]
    }
   ],
   "source": [
    "bestAlpha = grid_search.best_params_['alpha']\n",
    "bestNIterNoChange = grid_search.best_params_['n_iter_no_change']\n",
    "trigramTunedLogisticRegressor = SGDClassifier(\n",
    "                            loss='log_loss',\n",
    "                            alpha=bestAlpha,\n",
    "                            penalty='l2',\n",
    "                            max_iter=1000,\n",
    "                            learning_rate='optimal',\n",
    "                            n_iter_no_change=bestNIterNoChange,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)\n",
    "trigramTunedLogisticRegressor.fit(X_train_trigram, y_train)\n",
    "y_pred_trigram_tuned_logistic = trigramTunedLogisticRegressor.predict(X_test_trigram)\n",
    "print(\"trigram Tuned Logistic Regression Accuracy: \", 100*accuracy_score(y_test, y_pred_trigram_tuned_logistic))\n",
    "print(\"trigram Tuned Logistic Regression F1 Score: \", 100*f1_score(y_test, y_pred_trigram_tuned_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to paper, the default parameters to be used for SVM are $C=1.0$ and $kernel=linear$ unless specified otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Linear SVM Accuracy:  0.7339038808775878\n",
      "Unigram Linear SVM F1 Score:  0.6413282656531306\n"
     ]
    }
   ],
   "source": [
    "# X_train_unigram = load_npz(UNIGRAM_PATH + \"train.npz\")\n",
    "# X_test_unigram = load_npz(UNIGRAM_PATH + \"test.npz\")\n",
    "unigramLinearSVM = LinearSVC(C=1.0, max_iter=10000, random_state=42)\n",
    "unigramLinearSVM.fit(X_train_unigram, y_train)\n",
    "y_pred_unigram_linear_svm = unigramLinearSVM.predict(X_test_unigram)\n",
    "print(\"Unigram Linear SVM Accuracy: \", accuracy_score(y_test, y_pred_unigram_linear_svm))\n",
    "print(\"Unigram Linear SVM F1 Score: \", f1_score(y_test, y_pred_unigram_linear_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigram Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Linear SVM Accuracy:  0.7765465383759182\n",
      "Bigram Linear SVM F1 Score:  0.6993877279382404\n"
     ]
    }
   ],
   "source": [
    "# X_train_bigram = load_npz(BIGRAM_PATH + \"train.npz\")\n",
    "# X_test_bigram = load_npz(BIGRAM_PATH + \"test.npz\")\n",
    "bigramLinearSVM = LinearSVC(C=1.0, max_iter=10000, random_state=42)\n",
    "bigramLinearSVM.fit(X_train_bigram, y_train)\n",
    "y_pred_bigram_linear_svm = bigramLinearSVM.predict(X_test_bigram)\n",
    "print(\"Bigram Linear SVM Accuracy: \", accuracy_score(y_test, y_pred_bigram_linear_svm))\n",
    "print(\"Bigram Linear SVM F1 Score: \", f1_score(y_test, y_pred_bigram_linear_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigram Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Linear SVM Accuracy:  0.8075391426946004\n",
      "Trigram Linear SVM F1 Score:  0.7242637938977285\n"
     ]
    }
   ],
   "source": [
    "# X_train_trigram = load_npz(TRIGRAM_PATH + \"train.npz\")\n",
    "# X_test_trigram = load_npz(TRIGRAM_PATH + \"test.npz\")\n",
    "trigramLinearSVM = LinearSVC(C=0.1, max_iter=10000, random_state=42)\n",
    "trigramLinearSVM.fit(X_train_trigram, y_train)\n",
    "y_pred_trigram_linear_svm = trigramLinearSVM.predict(X_test_trigram)\n",
    "print(\"Trigram Linear SVM Accuracy: \", accuracy_score(y_test, y_pred_trigram_linear_svm))\n",
    "print(\"Trigram Linear SVM F1 Score: \", f1_score(y_test, y_pred_trigram_linear_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning for Trigram SVM Model with different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_trigram = load_npz(TRIGRAM_PATH + \"train.npz\")\n",
    "# X_test_trigram = load_npz(TRIGRAM_PATH + \"test.npz\")\n",
    "# X_val_trigram = load_npz(TRIGRAM_PATH + \"val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 28 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=SVC(max_iter=5000, random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.001, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=SVC(max_iter=5000, random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.001, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;f1&#x27;], verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
       "             estimator=SVC(max_iter=5000, random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.001, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "             refit='accuracy', scoring=['accuracy', 'f1'], verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = dict({\n",
    "                    'C':[0.005, 0.001, 0.1, 0.5, 1.0, 10, 50], \n",
    "                    'kernel':['linear', 'rbf', 'poly', 'sigmoid']\n",
    "                })\n",
    "trigramSVM = SVC(max_iter=5000, random_state=42)\n",
    "cv_stratified_splitter = StratifiedKFold(n_splits=2)\n",
    "grid_search = GridSearchCV(trigramSVM, \n",
    "                            parameters, \n",
    "                            cv=cv_stratified_splitter, \n",
    "                            scoring=['accuracy', 'f1'], \n",
    "                            n_jobs=-1,\n",
    "                            refit='accuracy',\n",
    "                            verbose=1)\n",
    "grid_search.fit(sparse_vstack([X_train_trigram, X_val_trigram]), np.concatenate((y_train, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1269.840520</td>\n",
       "      <td>33.217703</td>\n",
       "      <td>496.621304</td>\n",
       "      <td>2.677389</td>\n",
       "      <td>0.005</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.005, 'kernel': 'linear'}</td>\n",
       "      <td>0.372685</td>\n",
       "      <td>0.369268</td>\n",
       "      <td>0.370977</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>22</td>\n",
       "      <td>0.540522</td>\n",
       "      <td>0.539318</td>\n",
       "      <td>0.539920</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282.469714</td>\n",
       "      <td>30.366632</td>\n",
       "      <td>477.714923</td>\n",
       "      <td>7.902120</td>\n",
       "      <td>0.005</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.005, 'kernel': 'rbf'}</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>0.515374</td>\n",
       "      <td>0.558197</td>\n",
       "      <td>0.042823</td>\n",
       "      <td>11</td>\n",
       "      <td>0.524347</td>\n",
       "      <td>0.550310</td>\n",
       "      <td>0.537329</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1258.852223</td>\n",
       "      <td>24.312050</td>\n",
       "      <td>482.105273</td>\n",
       "      <td>2.530365</td>\n",
       "      <td>0.005</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.005, 'kernel': 'poly'}</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>0.369197</td>\n",
       "      <td>0.369199</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>28</td>\n",
       "      <td>0.539293</td>\n",
       "      <td>0.539290</td>\n",
       "      <td>0.539292</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1313.461902</td>\n",
       "      <td>23.086716</td>\n",
       "      <td>555.533464</td>\n",
       "      <td>7.870833</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.005, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.389230</td>\n",
       "      <td>0.371027</td>\n",
       "      <td>0.380129</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>21</td>\n",
       "      <td>0.544587</td>\n",
       "      <td>0.539890</td>\n",
       "      <td>0.542238</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1264.621557</td>\n",
       "      <td>28.248824</td>\n",
       "      <td>490.529670</td>\n",
       "      <td>1.299316</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>0.370992</td>\n",
       "      <td>0.369785</td>\n",
       "      <td>0.370389</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>23</td>\n",
       "      <td>0.539908</td>\n",
       "      <td>0.539492</td>\n",
       "      <td>0.539700</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1284.942240</td>\n",
       "      <td>30.085127</td>\n",
       "      <td>483.316809</td>\n",
       "      <td>7.461044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.599777</td>\n",
       "      <td>0.514225</td>\n",
       "      <td>0.557001</td>\n",
       "      <td>0.042776</td>\n",
       "      <td>12</td>\n",
       "      <td>0.526669</td>\n",
       "      <td>0.549251</td>\n",
       "      <td>0.537960</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1137.083540</td>\n",
       "      <td>19.191614</td>\n",
       "      <td>515.709534</td>\n",
       "      <td>13.700713</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>0.369415</td>\n",
       "      <td>0.369197</td>\n",
       "      <td>0.369306</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>26</td>\n",
       "      <td>0.539374</td>\n",
       "      <td>0.539290</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1172.080629</td>\n",
       "      <td>26.647017</td>\n",
       "      <td>594.919960</td>\n",
       "      <td>3.235845</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.391110</td>\n",
       "      <td>0.382130</td>\n",
       "      <td>0.386620</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>19</td>\n",
       "      <td>0.544888</td>\n",
       "      <td>0.542999</td>\n",
       "      <td>0.543944</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1119.065827</td>\n",
       "      <td>21.330025</td>\n",
       "      <td>578.916634</td>\n",
       "      <td>4.447443</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.498425</td>\n",
       "      <td>0.560903</td>\n",
       "      <td>0.529664</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>14</td>\n",
       "      <td>0.544728</td>\n",
       "      <td>0.553033</td>\n",
       "      <td>0.548881</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1147.327423</td>\n",
       "      <td>23.515550</td>\n",
       "      <td>485.715543</td>\n",
       "      <td>0.260239</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.600821</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.564386</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>10</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.546554</td>\n",
       "      <td>0.548213</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1125.386376</td>\n",
       "      <td>12.957276</td>\n",
       "      <td>496.366135</td>\n",
       "      <td>8.329908</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>0.369365</td>\n",
       "      <td>0.369235</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>27</td>\n",
       "      <td>0.539351</td>\n",
       "      <td>0.539305</td>\n",
       "      <td>0.539328</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1277.802000</td>\n",
       "      <td>6.340490</td>\n",
       "      <td>760.808654</td>\n",
       "      <td>8.159504</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.451649</td>\n",
       "      <td>0.456379</td>\n",
       "      <td>0.454014</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>17</td>\n",
       "      <td>0.555709</td>\n",
       "      <td>0.557947</td>\n",
       "      <td>0.556828</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1098.563245</td>\n",
       "      <td>7.149368</td>\n",
       "      <td>594.772163</td>\n",
       "      <td>0.596776</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'linear'}</td>\n",
       "      <td>0.570590</td>\n",
       "      <td>0.602798</td>\n",
       "      <td>0.586694</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>6</td>\n",
       "      <td>0.527961</td>\n",
       "      <td>0.521415</td>\n",
       "      <td>0.524688</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1165.459089</td>\n",
       "      <td>28.966205</td>\n",
       "      <td>501.875090</td>\n",
       "      <td>9.207857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'rbf'}</td>\n",
       "      <td>0.625688</td>\n",
       "      <td>0.520997</td>\n",
       "      <td>0.573342</td>\n",
       "      <td>0.052345</td>\n",
       "      <td>9</td>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.535963</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1138.240542</td>\n",
       "      <td>26.465557</td>\n",
       "      <td>507.881487</td>\n",
       "      <td>7.254820</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'poly'}</td>\n",
       "      <td>0.369624</td>\n",
       "      <td>0.369395</td>\n",
       "      <td>0.369509</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>25</td>\n",
       "      <td>0.539442</td>\n",
       "      <td>0.539364</td>\n",
       "      <td>0.539403</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1342.924403</td>\n",
       "      <td>12.204080</td>\n",
       "      <td>922.961548</td>\n",
       "      <td>8.867664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.484162</td>\n",
       "      <td>0.486621</td>\n",
       "      <td>0.485391</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>16</td>\n",
       "      <td>0.559724</td>\n",
       "      <td>0.561929</td>\n",
       "      <td>0.560826</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1073.436984</td>\n",
       "      <td>1.925413</td>\n",
       "      <td>552.022081</td>\n",
       "      <td>15.596321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear'}</td>\n",
       "      <td>0.562373</td>\n",
       "      <td>0.595218</td>\n",
       "      <td>0.578795</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>8</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>0.522927</td>\n",
       "      <td>0.523089</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1187.731697</td>\n",
       "      <td>24.546043</td>\n",
       "      <td>506.190025</td>\n",
       "      <td>7.278024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'rbf'}</td>\n",
       "      <td>0.623616</td>\n",
       "      <td>0.615264</td>\n",
       "      <td>0.619440</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516856</td>\n",
       "      <td>0.493791</td>\n",
       "      <td>0.505324</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1141.941709</td>\n",
       "      <td>9.473703</td>\n",
       "      <td>485.608826</td>\n",
       "      <td>7.192558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'poly'}</td>\n",
       "      <td>0.370162</td>\n",
       "      <td>0.369966</td>\n",
       "      <td>0.370064</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>24</td>\n",
       "      <td>0.539650</td>\n",
       "      <td>0.539563</td>\n",
       "      <td>0.539607</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1419.882024</td>\n",
       "      <td>16.956376</td>\n",
       "      <td>880.958027</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.489422</td>\n",
       "      <td>0.493745</td>\n",
       "      <td>0.491583</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>15</td>\n",
       "      <td>0.559951</td>\n",
       "      <td>0.562807</td>\n",
       "      <td>0.561379</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1017.253214</td>\n",
       "      <td>5.085919</td>\n",
       "      <td>507.510478</td>\n",
       "      <td>29.088173</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.591980</td>\n",
       "      <td>0.579131</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>7</td>\n",
       "      <td>0.524900</td>\n",
       "      <td>0.513089</td>\n",
       "      <td>0.518995</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1094.241096</td>\n",
       "      <td>24.548651</td>\n",
       "      <td>490.940744</td>\n",
       "      <td>7.293171</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.667550</td>\n",
       "      <td>0.662321</td>\n",
       "      <td>0.664935</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.362041</td>\n",
       "      <td>0.403391</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1068.490161</td>\n",
       "      <td>10.411989</td>\n",
       "      <td>491.860149</td>\n",
       "      <td>5.340801</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'kernel': 'poly'}</td>\n",
       "      <td>0.386658</td>\n",
       "      <td>0.385330</td>\n",
       "      <td>0.385994</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>20</td>\n",
       "      <td>0.543813</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>0.543598</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1481.041302</td>\n",
       "      <td>27.874655</td>\n",
       "      <td>723.998810</td>\n",
       "      <td>18.073873</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.610754</td>\n",
       "      <td>0.581158</td>\n",
       "      <td>0.595956</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.554052</td>\n",
       "      <td>0.543572</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>862.874676</td>\n",
       "      <td>118.905954</td>\n",
       "      <td>348.162206</td>\n",
       "      <td>39.578675</td>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 50, 'kernel': 'linear'}</td>\n",
       "      <td>0.559366</td>\n",
       "      <td>0.542379</td>\n",
       "      <td>0.550872</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>13</td>\n",
       "      <td>0.523137</td>\n",
       "      <td>0.509991</td>\n",
       "      <td>0.516564</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1072.420063</td>\n",
       "      <td>16.491667</td>\n",
       "      <td>316.115345</td>\n",
       "      <td>12.673885</td>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'kernel': 'rbf'}</td>\n",
       "      <td>0.664972</td>\n",
       "      <td>0.662183</td>\n",
       "      <td>0.663578</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325454</td>\n",
       "      <td>0.417577</td>\n",
       "      <td>0.371515</td>\n",
       "      <td>0.046062</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1019.736550</td>\n",
       "      <td>3.352032</td>\n",
       "      <td>303.797428</td>\n",
       "      <td>23.847761</td>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 50, 'kernel': 'poly'}</td>\n",
       "      <td>0.414668</td>\n",
       "      <td>0.409031</td>\n",
       "      <td>0.411850</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>18</td>\n",
       "      <td>0.548178</td>\n",
       "      <td>0.548129</td>\n",
       "      <td>0.548153</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1001.142618</td>\n",
       "      <td>24.544942</td>\n",
       "      <td>331.169699</td>\n",
       "      <td>6.508735</td>\n",
       "      <td>50</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 50, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.620757</td>\n",
       "      <td>0.563568</td>\n",
       "      <td>0.592163</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516313</td>\n",
       "      <td>0.561733</td>\n",
       "      <td>0.539023</td>\n",
       "      <td>0.022710</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     1269.840520     33.217703       496.621304        2.677389   0.005   \n",
       "1     1282.469714     30.366632       477.714923        7.902120   0.005   \n",
       "2     1258.852223     24.312050       482.105273        2.530365   0.005   \n",
       "3     1313.461902     23.086716       555.533464        7.870833   0.005   \n",
       "4     1264.621557     28.248824       490.529670        1.299316   0.001   \n",
       "5     1284.942240     30.085127       483.316809        7.461044   0.001   \n",
       "6     1137.083540     19.191614       515.709534       13.700713   0.001   \n",
       "7     1172.080629     26.647017       594.919960        3.235845   0.001   \n",
       "8     1119.065827     21.330025       578.916634        4.447443     0.1   \n",
       "9     1147.327423     23.515550       485.715543        0.260239     0.1   \n",
       "10    1125.386376     12.957276       496.366135        8.329908     0.1   \n",
       "11    1277.802000      6.340490       760.808654        8.159504     0.1   \n",
       "12    1098.563245      7.149368       594.772163        0.596776     0.5   \n",
       "13    1165.459089     28.966205       501.875090        9.207857     0.5   \n",
       "14    1138.240542     26.465557       507.881487        7.254820     0.5   \n",
       "15    1342.924403     12.204080       922.961548        8.867664     0.5   \n",
       "16    1073.436984      1.925413       552.022081       15.596321     1.0   \n",
       "17    1187.731697     24.546043       506.190025        7.278024     1.0   \n",
       "18    1141.941709      9.473703       485.608826        7.192558     1.0   \n",
       "19    1419.882024     16.956376       880.958027        0.060140     1.0   \n",
       "20    1017.253214      5.085919       507.510478       29.088173      10   \n",
       "21    1094.241096     24.548651       490.940744        7.293171      10   \n",
       "22    1068.490161     10.411989       491.860149        5.340801      10   \n",
       "23    1481.041302     27.874655       723.998810       18.073873      10   \n",
       "24     862.874676    118.905954       348.162206       39.578675      50   \n",
       "25    1072.420063     16.491667       316.115345       12.673885      50   \n",
       "26    1019.736550      3.352032       303.797428       23.847761      50   \n",
       "27    1001.142618     24.544942       331.169699        6.508735      50   \n",
       "\n",
       "   param_kernel                             params  split0_test_accuracy  \\\n",
       "0        linear   {'C': 0.005, 'kernel': 'linear'}              0.372685   \n",
       "1           rbf      {'C': 0.005, 'kernel': 'rbf'}              0.601019   \n",
       "2          poly     {'C': 0.005, 'kernel': 'poly'}              0.369200   \n",
       "3       sigmoid  {'C': 0.005, 'kernel': 'sigmoid'}              0.389230   \n",
       "4        linear   {'C': 0.001, 'kernel': 'linear'}              0.370992   \n",
       "5           rbf      {'C': 0.001, 'kernel': 'rbf'}              0.599777   \n",
       "6          poly     {'C': 0.001, 'kernel': 'poly'}              0.369415   \n",
       "7       sigmoid  {'C': 0.001, 'kernel': 'sigmoid'}              0.391110   \n",
       "8        linear     {'C': 0.1, 'kernel': 'linear'}              0.498425   \n",
       "9           rbf        {'C': 0.1, 'kernel': 'rbf'}              0.600821   \n",
       "10         poly       {'C': 0.1, 'kernel': 'poly'}              0.369365   \n",
       "11      sigmoid    {'C': 0.1, 'kernel': 'sigmoid'}              0.451649   \n",
       "12       linear     {'C': 0.5, 'kernel': 'linear'}              0.570590   \n",
       "13          rbf        {'C': 0.5, 'kernel': 'rbf'}              0.625688   \n",
       "14         poly       {'C': 0.5, 'kernel': 'poly'}              0.369624   \n",
       "15      sigmoid    {'C': 0.5, 'kernel': 'sigmoid'}              0.484162   \n",
       "16       linear     {'C': 1.0, 'kernel': 'linear'}              0.562373   \n",
       "17          rbf        {'C': 1.0, 'kernel': 'rbf'}              0.623616   \n",
       "18         poly       {'C': 1.0, 'kernel': 'poly'}              0.370162   \n",
       "19      sigmoid    {'C': 1.0, 'kernel': 'sigmoid'}              0.489422   \n",
       "20       linear      {'C': 10, 'kernel': 'linear'}              0.566281   \n",
       "21          rbf         {'C': 10, 'kernel': 'rbf'}              0.667550   \n",
       "22         poly        {'C': 10, 'kernel': 'poly'}              0.386658   \n",
       "23      sigmoid     {'C': 10, 'kernel': 'sigmoid'}              0.610754   \n",
       "24       linear      {'C': 50, 'kernel': 'linear'}              0.559366   \n",
       "25          rbf         {'C': 50, 'kernel': 'rbf'}              0.664972   \n",
       "26         poly        {'C': 50, 'kernel': 'poly'}              0.414668   \n",
       "27      sigmoid     {'C': 50, 'kernel': 'sigmoid'}              0.620757   \n",
       "\n",
       "    split1_test_accuracy  mean_test_accuracy  std_test_accuracy  \\\n",
       "0               0.369268            0.370977           0.001708   \n",
       "1               0.515374            0.558197           0.042823   \n",
       "2               0.369197            0.369199           0.000002   \n",
       "3               0.371027            0.380129           0.009101   \n",
       "4               0.369785            0.370389           0.000604   \n",
       "5               0.514225            0.557001           0.042776   \n",
       "6               0.369197            0.369306           0.000109   \n",
       "7               0.382130            0.386620           0.004490   \n",
       "8               0.560903            0.529664           0.031239   \n",
       "9               0.527950            0.564386           0.036435   \n",
       "10              0.369235            0.369300           0.000065   \n",
       "11              0.456379            0.454014           0.002365   \n",
       "12              0.602798            0.586694           0.016104   \n",
       "13              0.520997            0.573342           0.052345   \n",
       "14              0.369395            0.369509           0.000114   \n",
       "15              0.486621            0.485391           0.001230   \n",
       "16              0.595218            0.578795           0.016423   \n",
       "17              0.615264            0.619440           0.004176   \n",
       "18              0.369966            0.370064           0.000098   \n",
       "19              0.493745            0.491583           0.002162   \n",
       "20              0.591980            0.579131           0.012850   \n",
       "21              0.662321            0.664935           0.002615   \n",
       "22              0.385330            0.385994           0.000664   \n",
       "23              0.581158            0.595956           0.014798   \n",
       "24              0.542379            0.550872           0.008493   \n",
       "25              0.662183            0.663578           0.001394   \n",
       "26              0.409031            0.411850           0.002819   \n",
       "27              0.563568            0.592163           0.028594   \n",
       "\n",
       "    rank_test_accuracy  split0_test_f1  split1_test_f1  mean_test_f1  \\\n",
       "0                   22        0.540522        0.539318      0.539920   \n",
       "1                   11        0.524347        0.550310      0.537329   \n",
       "2                   28        0.539293        0.539290      0.539292   \n",
       "3                   21        0.544587        0.539890      0.542238   \n",
       "4                   23        0.539908        0.539492      0.539700   \n",
       "5                   12        0.526669        0.549251      0.537960   \n",
       "6                   26        0.539374        0.539290      0.539332   \n",
       "7                   19        0.544888        0.542999      0.543944   \n",
       "8                   14        0.544728        0.553033      0.548881   \n",
       "9                   10        0.549873        0.546554      0.548213   \n",
       "10                  27        0.539351        0.539305      0.539328   \n",
       "11                  17        0.555709        0.557947      0.556828   \n",
       "12                   6        0.527961        0.521415      0.524688   \n",
       "13                   9        0.521867        0.550059      0.535963   \n",
       "14                  25        0.539442        0.539364      0.539403   \n",
       "15                  16        0.559724        0.561929      0.560826   \n",
       "16                   8        0.523251        0.522927      0.523089   \n",
       "17                   3        0.516856        0.493791      0.505324   \n",
       "18                  24        0.539650        0.539563      0.539607   \n",
       "19                  15        0.559951        0.562807      0.561379   \n",
       "20                   7        0.524900        0.513089      0.518995   \n",
       "21                   1        0.362041        0.403391      0.382716   \n",
       "22                  20        0.543813        0.543382      0.543598   \n",
       "23                   4        0.533092        0.554052      0.543572   \n",
       "24                  13        0.523137        0.509991      0.516564   \n",
       "25                   2        0.325454        0.417577      0.371515   \n",
       "26                  18        0.548178        0.548129      0.548153   \n",
       "27                   5        0.516313        0.561733      0.539023   \n",
       "\n",
       "    std_test_f1  rank_test_f1  \n",
       "0      0.000602            11  \n",
       "1      0.012981            20  \n",
       "2      0.000002            17  \n",
       "3      0.002349            10  \n",
       "4      0.000208            12  \n",
       "5      0.011291            19  \n",
       "6      0.000042            15  \n",
       "7      0.000945             7  \n",
       "8      0.004153             4  \n",
       "9      0.001660             5  \n",
       "10     0.000023            16  \n",
       "11     0.001119             3  \n",
       "12     0.003273            22  \n",
       "13     0.014096            21  \n",
       "14     0.000039            14  \n",
       "15     0.001102             2  \n",
       "16     0.000162            23  \n",
       "17     0.011532            26  \n",
       "18     0.000043            13  \n",
       "19     0.001428             1  \n",
       "20     0.005905            24  \n",
       "21     0.020675            27  \n",
       "22     0.000215             8  \n",
       "23     0.010480             9  \n",
       "24     0.006573            25  \n",
       "25     0.046062            28  \n",
       "26     0.000024             6  \n",
       "27     0.022710            18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCVResults = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "gridSearchCVResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Best Parameters</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Tuned SVM Accuracy:  0.6275445843330283\n",
      "Trigram Tuned SVM F1 Score:  0.365177065767285\n"
     ]
    }
   ],
   "source": [
    "bestC=grid_search.best_params_['C']\n",
    "bestKernel=grid_search.best_params_['kernel']\n",
    "trigramTunedSVM = SVC(C=bestC, kernel=bestKernel, max_iter=5000, random_state=42)\n",
    "trigramTunedSVM.fit(X_train_trigram, y_train)\n",
    "y_pred_trigram_tuned_svm = trigramTunedSVM.predict(X_test_trigram)\n",
    "print(\"Trigram Tuned SVM Accuracy: \", accuracy_score(y_test, y_pred_trigram_tuned_svm))\n",
    "print(\"Trigram Tuned SVM F1 Score: \", f1_score(y_test, y_pred_trigram_tuned_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embeddings as feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50-dimensional word vectors are obtained using GloVe vectors (GloVe.6B.50d.txt). The sentence embeddings are obtained by simply summing the word embeddings in a sentence. The sentence embeddings are then used as feature vectors for classification in the following two ways:\n",
    "- Plain sentence embeddings\n",
    "- Distance measure between vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = INPUT + 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessAndTokenizeForGlove(text: str) -> list[str]:\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text.lower())\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [stemmer.stem(w) for w in tokens if stemmer.stem(w) not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "preprocessorAndTokenizor = np.vectorize(preprocessAndTokenizeForGlove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train_q1_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_train_q1], dtype=object)\n",
    "    X_train_q2_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_train_q2], dtype=object)\n",
    "    X_test_q1_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_test_q1], dtype=object)\n",
    "    X_test_q2_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_test_q2], dtype=object)\n",
    "    X_val_q1_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_val_q1], dtype=object)\n",
    "    X_val_q2_tokenized = np.array([preprocessAndTokenizeForGlove(ques) for ques in X_val_q2], dtype=object)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe Word Embeddings\n",
    "GloVe_embeddings = {}\n",
    "with open(GLOVE_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        GloVe_embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sentence embeddings for each question\n",
    "\n",
    "According to the paper, the sentence embeddings are obtained by simply summing the embeddings of all the tokens in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_q1_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_train_q1_tokenized])\n",
    "X_train_q2_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_train_q2_tokenized])\n",
    "X_test_q1_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_test_q1_tokenized])\n",
    "X_test_q2_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_test_q2_tokenized])\n",
    "X_val_q1_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_val_q1_tokenized])\n",
    "X_val_q2_embeddings = np.array([np.sum([GloVe_embeddings[w] for w in ques if w in GloVe_embeddings] + [np.zeros((50,))], axis=0) for ques in X_val_q2_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_EMBEDDINGS = './question_embeddings/'\n",
    "os.makedirs(QUESTION_EMBEDDINGS, exist_ok=True)\n",
    "TRAIN_Q1_EMBEDDINGS = QUESTION_EMBEDDINGS + 'train_q1_embeddings.npz'\n",
    "TRAIN_Q2_EMBEDDINGS = QUESTION_EMBEDDINGS + 'train_q2_embeddings.npz'\n",
    "TEST_Q1_EMBEDDINGS = QUESTION_EMBEDDINGS + 'test_q1_embeddings.npz'\n",
    "TEST_Q2_EMBEDDINGS = QUESTION_EMBEDDINGS + 'test_q2_embeddings.npz'\n",
    "VAL_Q1_EMBEDDINGS = QUESTION_EMBEDDINGS + 'val_q1_embeddings.npz'\n",
    "VAL_Q2_EMBEDDINGS = QUESTION_EMBEDDINGS + 'val_q2_embeddings.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(TRAIN_Q1_EMBEDDINGS, X_train_q1_embeddings)\n",
    "np.savez_compressed(TRAIN_Q2_EMBEDDINGS, X_train_q2_embeddings)\n",
    "np.savez_compressed(TEST_Q1_EMBEDDINGS, X_test_q1_embeddings)\n",
    "np.savez_compressed(TEST_Q2_EMBEDDINGS, X_test_q2_embeddings)\n",
    "np.savez_compressed(VAL_Q1_EMBEDDINGS, X_val_q1_embeddings)\n",
    "np.savez_compressed(VAL_Q2_EMBEDDINGS, X_val_q2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_q1_embeddings = np.load(TRAIN_Q1_EMBEDDINGS)['arr_0']\n",
    "# X_train_q2_embeddings = np.load(TRAIN_Q2_EMBEDDINGS)['arr_0']\n",
    "# X_test_q1_embeddings = np.load(TEST_Q1_EMBEDDINGS)['arr_0']\n",
    "# X_test_q2_embeddings = np.load(TEST_Q2_EMBEDDINGS)['arr_0']\n",
    "# X_val_q1_embeddings = np.load(VAL_Q1_EMBEDDINGS)['arr_0']\n",
    "# X_val_q2_embeddings = np.load(VAL_Q2_EMBEDDINGS)['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plain sentence embeddings\n",
    "\n",
    "$100$-dimensional feature vector = $50$-dimensional question $1$ sentence embedding + $50$-dimensional question $2$ sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plain_embeddings = np.hstack((X_train_q1_embeddings, X_train_q2_embeddings))\n",
    "X_test_plain_embeddings = np.hstack((X_test_q1_embeddings, X_test_q2_embeddings))\n",
    "X_val_plain_embeddings = np.hstack((X_val_q1_embeddings, X_val_q2_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4918499097182715\n",
      "F1 Score: 0.5580414766371224\n"
     ]
    }
   ],
   "source": [
    "SVMmodel = SVC(kernel='rbf', C=0.19, random_state=42, max_iter=3500)\n",
    "SVMmodel.fit(X_train_plain_embeddings, y_train)\n",
    "y_pred = SVMmodel.predict(X_test_plain_embeddings)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283003, 100), (40429, 100), (80858, 100))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_plain_embeddings.shape, X_test_plain_embeddings.shape, X_val_plain_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48846125306092164\n",
      "F1 Score: 0.5588053333333333\n"
     ]
    }
   ],
   "source": [
    "SVMmodel = SVC(kernel='rbf', C=1.0, random_state=42, max_iter=3500)\n",
    "SVMmodel.fit(X_train_plain_embeddings, y_train)\n",
    "y_pred = SVMmodel.predict(X_test_plain_embeddings)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(max_iter=3500, random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(max_iter=3500, random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.005, 0.01, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=3500, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=3500, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(max_iter=3500, random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.005, 0.01, 0.1, 0.5, 1.0, 10, 50],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C': [0.005, 0.01, 0.1, 0.5, 1.0, 10, 50],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "plainEmbeddingSVM = SVC(max_iter=3500, random_state=42)\n",
    "cv_stratified_splitter = StratifiedKFold(n_splits=5)\n",
    "plainEmbeddingSVMGridSearch = GridSearchCV(plainEmbeddingSVM, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "plainEmbeddingSVMGridSearch.fit(X_train_plain_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('plainEmbeddingSVMGridSearch.pkl', 'wb') as f:\n",
    "    pickle.dump(plainEmbeddingSVMGridSearch, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 50, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plainEmbeddingSVMGridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6034883332793319"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plainEmbeddingSVMGridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Distance measure between vectors\n",
    "Feature vector is obtained by taking various distance measures between the sentence embeddings of the two questions:\n",
    "- Bray Curtis distance:\n",
    "$$\n",
    "d_{Bray Curtis} = \\frac{1}{2} \\sum_{i=1}^{50} \\frac{|q_1[i] - q_2[i]|}{|q_1[i] + q_2[i]|}\n",
    "$$\n",
    "- Canberra distance:\n",
    "$$\n",
    "d_{Canberra} = \\sum_{i=1}^{50} \\frac{|q_1[i] - q_2[i]|}{|q_1[i]| + |q_2[i]|}\n",
    "$$\n",
    "- Chebyshev distance:\n",
    "$$d_{Chebyshev} = max(|q_1[i] - q_2[i]|)$$\n",
    "- City block distance:\n",
    "$$d_{City block} = \\sum_{i=1}^{50} |q_1[i] - q_2[i]|$$\n",
    "- Correlation distance:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d_{Correlation} = 1 - \\frac{\\sum_{i=1}^{50} (q_1[i] - \\bar{q_1})(q_2[i] - \\bar{q_2})}{\\sqrt{\\sum_{i=1}^{50} (q_1[i] - \\bar{q_1})^2} \\sqrt{\\sum_{i=1}^{50} (q_2[i] - \\bar{q_2})^2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "- Cosine distance: \n",
    "$$\n",
    "d_{Cosine} = 1 - \\frac{\\sum_{i=1}^{50} q_1[i]q_2[i]}{\\sqrt{\\sum_{i=1}^{50} q_1[i]^2} \\sqrt{\\sum_{i=1}^{50} q_2[i]^2}}\n",
    "$$\n",
    "- Euclidean distance:\n",
    "$$d_{Euclidean} = \\sqrt{\\sum_{i=1}^{50} (q_1[i] - q_2[i])^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/scipy/spatial/distance.py:1155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n",
      "/home/nemesis/.local/lib/python3.10/site-packages/scipy/spatial/distance.py:620: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial.distance as scipyDistance\n",
    "\n",
    "def distances(q1, q2):\n",
    "    distanceFeatureVector = np.array([\n",
    "        scipyDistance.braycurtis(q1, q2),\n",
    "        scipyDistance.canberra(q1, q2),\n",
    "        scipyDistance.chebyshev(q1, q2),\n",
    "        scipyDistance.cityblock(q1, q2),\n",
    "        scipyDistance.correlation(q1, q2),\n",
    "        scipyDistance.cosine(q1, q2),\n",
    "        scipyDistance.euclidean(q1, q2)\n",
    "    ])\n",
    "    distanceFeatureVector = np.nan_to_num(distanceFeatureVector)\n",
    "    return distanceFeatureVector\n",
    "\n",
    "\n",
    "X_train_distances = np.array([distances(q1, q2) for q1, q2 in zip(X_train_q1_embeddings, X_train_q2_embeddings)])\n",
    "X_test_distances = np.array([distances(q1, q2) for q1, q2 in zip(X_test_q1_embeddings, X_test_q2_embeddings)])\n",
    "X_val_distances = np.array([distances(q1, q2) for q1, q2 in zip(X_val_q1_embeddings, X_val_q2_embeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40960696529718765\n",
      "F1 Score: 0.5550895636451753\n"
     ]
    }
   ],
   "source": [
    "distanceSVM = SVC(kernel='rbf', C=50, random_state=42, max_iter=3500)\n",
    "distanceSVM.fit(X_train_distances, y_train)\n",
    "y_pred = distanceSVM.predict(X_test_distances)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37020455613544734\n",
      "F1 Score: 0.5396825396825397\n"
     ]
    }
   ],
   "source": [
    "distanceSVM = SVC(kernel='linear', C=1.0, random_state=42, max_iter=3500)\n",
    "distanceSVM.fit(X_train_distances, y_train)\n",
    "y_pred = distanceSVM.predict(X_test_distances)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3794306067426847\n",
      "F1 Score: 0.5432633667692195\n"
     ]
    }
   ],
   "source": [
    "distanceSVM = SVC(kernel='linear', C=10, random_state=42, max_iter=3500)\n",
    "distanceSVM.fit(X_train_distances, y_train)\n",
    "y_pred = distanceSVM.predict(X_test_distances)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemesis/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=3500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3794306067426847\n",
      "F1 Score: 0.5432633667692195\n"
     ]
    }
   ],
   "source": [
    "distanceSVM = SVC(kernel='linear', C=50, random_state=42, max_iter=3500)\n",
    "distanceSVM.fit(X_train_distances, y_train)\n",
    "y_pred = distanceSVM.predict(X_test_distances)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
